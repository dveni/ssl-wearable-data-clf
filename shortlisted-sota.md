# Self-supervised learning for wearable sensors data classification

## References
> _A not comprehensive list_

- [Sense and Learn: Self-Supervision for Omnipresent Sensors](https://arxiv.org/pdf/2009.13233v1.pdf)(2020)
- [Trends in human activity recognition using smartphones](https://www.researchgate.net/publication/352949846_Trends_in_human_activity_recognition_using_smartphones)(2021)
- [Federated Self-Supervised Learning of Multisensor Representations for Embedded Intelligence](https://ieeexplore.ieee.org/document/9141293)(2021)
- [SelfHAR: Improving Human Activity Recognition through Self-training with Unlabeled Data](https://dl.acm.org/doi/10.1145/3448112)(2021)
- [Exploring Contrastive Learning in Human Activity Recognition for Healthcare](https://arxiv.org/pdf/2011.11542.pdf)(2021)
- [Self-supervised transfer learning of physiological representations from free-living wearable data](https://dl.acm.org/doi/10.1145/3450439.3451863)(2021)
- [A robust human activity recognition system using smartphone sensors and deep learning](https://www.sciencedirect.com/science/article/abs/pii/S0167739X17317351?via%3Dihub)(2018)
- [Deep Learning for Sensor-Based Activity Recognition: Recent Trends](https://link.springer.com/chapter/10.1007%2F978-3-030-51379-5_9)(2020)
- [Deep learning for sensor-based activity recognition: A survey](https://www.sciencedirect.com/science/article/abs/pii/S016786551830045X?via%3Dihub)(2019)
- [Deep Learning for Sensor-based Human Activity Recognition: Overview, Challenges, and Opportunities](https://dl.acm.org/doi/10.1145/3447744)(2021)
- [Unsupervised Learning for Product Use Activity Recognition: An Exploratory Study of a “Chatty Device”](https://www.mdpi.com/1424-8220/21/15/4991)(2021)
- [Unsupervised Human Activity Representation Learning with Multi-task Deep Clustering](https://dl.acm.org/doi/10.1145/3448074)(2021)
- [Few-shot learning-based human activity recognition](https://www.sciencedirect.com/science/article/abs/pii/S0957417419304786?via%3Dihub)(2019)

## Datasets
> _Another not comprehensive list_

- **[Human Activity Recognition Using Smartphones Data Set](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)**(2012): recordings of 30 subjects performing 6 different activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors((accelerometer and gyroscope).
- **[Smartphone-Based Recognition of Human Activities and Postural Transitions Data Set](http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions)**(2015): updated version of the UCI Human Activity Recognition Using smartphones Dataset.
- **[MotionSense Dataset](https://github.com/mmalekzadeh/motion-sense)**(2018): time-series data generated by accelerometer and gyroscope sensors of an iPhone 6s kept in the participant's front pocket.
- **[WISDM Smartphone and Smartwatch Activity and Biometrics Dataset Data Set](https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+)**(2019): Contains accelerometer and gyroscope time-series sensor data collected from a smartphone and smartwatch as 51 test subjects perform 18 activities for 3 minutes each.
- **[Heterogeneity Activity Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition)**(2015):dataset devised to benchmark human activity recognition algorithms and gathered with a variety of different device models and use-scenarios, in order to reflect sensing heterogeneities to be expected in real deployments.
- **[Activity Recognition system based on Multisensor data fusion (AReM) Data Set](https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+system+based+on+Multisensor+data+fusion+(AReM))**(2016): This dataset contains temporal data from a Wireless Sensor Network worn by an actor performing the activities: bending, cycling, lying down, sitting, standing, walking.
- **[Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL) Data Set](https://archive.ics.uci.edu/ml/datasets/Smartphone+Dataset+for+Human+Activity+Recognition+%28HAR%29+in+Ambient+Assisted+Living+%28AAL%29)**(2016): This dataset is an addition to the _Human Activity Recognition Using Smartphones Data Set_ dataset.  collected from the in-built accelerometer and gyroscope of a smartphone worn around the waist of participants.
- **[Activity recognition with healthy older people using a batteryless wearable sensor Data Set](https://archive.ics.uci.edu/ml/datasets/Activity+recognition+with+healthy+older+people+using+a+batteryless+wearable+sensor)**(2016): Sequential motion data from 14 healthy older people aged 66 to 86 years old using a batteryless, wearable sensor on top of their clothing for the recognition of activities in clinical environments.
- **[OPPORTUNITY Activity Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/OPPORTUNITY+Activity+Recognition)**(2012):The dataset comprises the readings of motion sensors recorded while users executed typical daily activities: Body-worn sensors, Object sensors and ambient sensors.
- **[DataSet - RealWorld (HAR)](https://sensor.informatik.uni-mannheim.de/#dataset_realworld)**(2016): The data set covers acceleration, GPS, gyroscope, light, magnetic field, and sound level data of the activities climbing stairs down and up, jumping, lying, standing, sitting, running/jogging, and walking of fifteen subjects
